import 'dart:async';
import 'dart:io';
import 'package:camera/camera.dart';
import 'package:google_ml_kit/google_ml_kit.dart';
import 'package:flutter_local_notifications/flutter_local_notifications.dart';
import 'package:flutter/widgets.dart'; // TH√äM D√íNG N√ÄY

class FaceDetectionService {
  static final FaceDetectionService _instance =
      FaceDetectionService._internal();
  factory FaceDetectionService() => _instance;
  FaceDetectionService._internal();

  late CameraController _cameraController;
  final FaceDetector _faceDetector = GoogleMlKit.vision.faceDetector();
  Timer? _detectionTimer;
  bool _isDetecting = false;
  final FlutterLocalNotificationsPlugin _notifications =
      FlutterLocalNotificationsPlugin();

  // Bi·∫øn ƒë·∫øm s·ªë l·∫ßn ph√°t hi·ªán khu√¥n m·∫∑t li√™n ti·∫øp
  int _faceDetectionCount = 0;
  static const int _warningThreshold = 2;
  DateTime? _lastFaceDetectionTime;

  // Bi·∫øn ƒë·ªÉ tr√°nh c·∫£nh b√°o li√™n t·ª•c sau khi ƒë√£ c·∫£nh b√°o
  DateTime? _lastWarningTime;
  static const Duration _warningCooldown = Duration(seconds: 30);

  // Bi·∫øn l∆∞u tr·∫°ng th√°i app
  AppLifecycleState _currentAppState = AppLifecycleState.resumed; // ƒê√É S·ª¨A
  bool _lastFaceDetectedState = false;
  DateTime? _lastForegroundDetectionTime;

  Function(bool)? onFaceDetected;

  Future<void> initialize() async {
    await _setupCamera();
    await _setupNotifications();
  }

  Future<void> _setupCamera() async {
    try {
      final cameras = await availableCameras();
      final frontCamera = cameras.firstWhere(
        (camera) => camera.lensDirection == CameraLensDirection.front,
        orElse: () => cameras.first,
      );

      _cameraController = CameraController(
        frontCamera,
        ResolutionPreset.low,
        enableAudio: false,
      );

      await _cameraController.initialize();
    } catch (e) {
      print('Camera setup error: $e');
    }
  }

  Future<void> _setupNotifications() async {
    const AndroidInitializationSettings androidSettings =
        AndroidInitializationSettings('@mipmap/ic_launcher');

    const DarwinInitializationSettings iosSettings =
        DarwinInitializationSettings();

    const InitializationSettings settings = InitializationSettings(
      android: androidSettings,
      iOS: iosSettings,
    );

    await _notifications.initialize(settings);

    await _notifications
        .resolvePlatformSpecificImplementation<
          AndroidFlutterLocalNotificationsPlugin
        >()
        ?.createNotificationChannel(
          const AndroidNotificationChannel(
            'driving_safety_channel',
            'C·∫£nh b√°o an to√†n l√°i xe',
            importance: Importance.high,
            playSound: true,
          ),
        );
  }

  // Ph∆∞∆°ng th·ª©c m·ªõi: C·∫≠p nh·∫≠t tr·∫°ng th√°i app
  void updateAppState(AppLifecycleState state) {
    // ƒê√É S·ª¨A
    _currentAppState = state;
    print('üîÑ App state changed to: $state');

    if (state == AppLifecycleState.resumed) {
      // ƒê√É S·ª¨A
      print('üéØ App resumed - Camera ready for detection');
      // Kh·ªüi t·∫°o l·∫°i camera khi app tr·ªü l·∫°i foreground
      _initializeCameraIfNeeded();
    } else if (state == AppLifecycleState.paused ||
        state == AppLifecycleState.inactive) {
      // ƒê√É S·ª¨A
      print('‚è∏Ô∏è App in background - Disposing camera');
      _disposeCamera();
    }
  }

  Future<void> _initializeCameraIfNeeded() async {
    if (!_cameraController.value.isInitialized && _isDetecting) {
      await _setupCamera();
    }
  }

  Future<void> _disposeCamera() async {
    try {
      if (_cameraController.value.isInitialized) {
        await _cameraController.dispose();
        print('üì∑ Camera disposed');
      }
    } catch (e) {
      print('Error disposing camera: $e');
    }
  }

  Future<void> startFaceDetection() async {
    if (_isDetecting) return;

    _isDetecting = true;
    _resetDetectionCount();

    // B·∫Øt ƒë·∫ßu detection m·ªói 5 gi√¢y
    _detectionTimer = Timer.periodic(Duration(seconds: 5), (timer) async {
      await _performFaceDetection();
    });

    print('Face detection started');
  }

  Future<void> stopFaceDetection() async {
    _detectionTimer?.cancel();
    _detectionTimer = null;
    _isDetecting = false;
    _resetDetectionCount();
    await _disposeCamera();

    print('Face detection stopped');
  }

  void _resetDetectionCount() {
    _faceDetectionCount = 0;
    _lastFaceDetectionTime = null;
    print('Reset face detection count to 0');
  }

  Future<void> _performFaceDetection() async {
    try {
      // KI·ªÇM TRA APP STATE - QUAN TR·ªåNG
      if (_currentAppState != AppLifecycleState.resumed) {
        // ƒê√É S·ª¨A
        print('üì± App in background - Using background detection logic');
        await _backgroundDetectionLogic();
        return;
      }

      // APP ƒêANG ·ªû FOREGROUND - CH·∫†Y DETECTION TH·∫¨T
      if (!_cameraController.value.isInitialized) {
        await _setupCamera();
        if (!_cameraController.value.isInitialized) {
          return;
        }
      }

      print('üîç Performing REAL face detection in foreground');
      final XFile imageFile = await _cameraController.takePicture();
      final inputImage = InputImage.fromFilePath(imageFile.path);

      final List<Face> faces = await _faceDetector.processImage(inputImage);
      final faceDetected = faces.isNotEmpty;

      // L∆∞u tr·∫°ng th√°i cho background detection
      _lastFaceDetectedState = faceDetected;
      _lastForegroundDetectionTime = DateTime.now();

      // G·ªçi callback
      onFaceDetected?.call(faceDetected);

      if (faceDetected) {
        await _handleFaceDetected();
      } else {
        _resetDetectionCount();
      }

      // X√≥a file ·∫£nh t·∫°m
      try {
        await File(imageFile.path).delete();
      } catch (e) {
        print('Error deleting temp file: $e');
      }
    } catch (e) {
      print('‚ùå Error in face detection: $e');
      // N·∫øu l·ªói camera, dispose v√† th·ª≠ l·∫°i sau
      if (e is CameraException) {
        await _disposeCamera();
      }
    }
  }

  // LOGIC DETECTION TRONG BACKGROUND
  Future<void> _backgroundDetectionLogic() async {
    final now = DateTime.now();

    // N·∫øu v·ª´a m·ªõi c√≥ face detected ·ªü foreground, ti·∫øp t·ª•c ƒë·∫øm
    if (_lastFaceDetectedState &&
        _lastForegroundDetectionTime != null &&
        now.difference(_lastForegroundDetectionTime!) < Duration(seconds: 10)) {
      _faceDetectionCount++;
      print('üîÆ Background detection - Predictive count: $_faceDetectionCount');

      if (_faceDetectionCount >= _warningThreshold) {
        await _triggerWarning();
      }
    } else {
      // Reset n·∫øu ƒë√£ l√¢u kh√¥ng c√≥ detection
      _resetDetectionCount();
    }
  }

  Future<void> _handleFaceDetected() async {
    final now = DateTime.now();

    // Ki·ªÉm tra n·∫øu ƒë√£ qu√° l√¢u k·ªÉ t·ª´ l·∫ßn ph√°t hi·ªán cu·ªëi (qu√° 10 gi√¢y)
    if (_lastFaceDetectionTime != null &&
        now.difference(_lastFaceDetectionTime!) > Duration(seconds: 10)) {
      _resetDetectionCount();
    }

    // TƒÉng bi·∫øn ƒë·∫øm
    _faceDetectionCount++;
    _lastFaceDetectionTime = now;

    print('üëÅÔ∏è Face detected! Count: $_faceDetectionCount/$_warningThreshold');

    // Ki·ªÉm tra n·∫øu ƒë·∫°t ng∆∞·ª°ng c·∫£nh b√°o
    if (_faceDetectionCount >= _warningThreshold) {
      await _triggerWarning();
    }
  }

  Future<void> _triggerWarning() async {
    final now = DateTime.now();

    // Ki·ªÉm tra cooldown ƒë·ªÉ tr√°nh c·∫£nh b√°o li√™n t·ª•c
    if (_lastWarningTime != null &&
        now.difference(_lastWarningTime!) < _warningCooldown) {
      print('‚è≥ Warning cooldown active, skipping warning');
      return;
    }

    _lastWarningTime = now;

    print('üö® WARNING TRIGGERED - User continuously using phone while driving');

    // G·ª≠i notification c·∫£nh b√°o
    await _sendWarningNotification();

    // Log s·ª± ki·ªán
    await _logDrivingEvent();

    // Reset bi·∫øn ƒë·∫øm sau khi c·∫£nh b√°o
    _resetDetectionCount();
  }

  Future<void> _sendWarningNotification() async {
    const AndroidNotificationDetails androidDetails =
        AndroidNotificationDetails(
          'driving_safety_channel',
          'C·∫£nh b√°o an to√†n l√°i xe',
          channelDescription:
              'Th√¥ng b√°o khi ph√°t hi·ªán s·ª≠ d·ª•ng ƒëi·ªán tho·∫°i khi l√°i xe',
          importance: Importance.high,
          priority: Priority.high,
          playSound: true,
          enableVibration: true,
        );

    const DarwinNotificationDetails iosDetails = DarwinNotificationDetails(
      presentAlert: true,
      presentBadge: true,
      presentSound: true,
    );

    const NotificationDetails details = NotificationDetails(
      android: androidDetails,
      iOS: iosDetails,
    );

    await _notifications.show(
      1,
      'üö® C·∫¢NH B√ÅO AN TO√ÄN',
      'PH√ÅT HI·ªÜN S·ª¨ D·ª§NG ƒêI·ªÜN THO·∫†I LI√äN T·ª§C KHI ƒêANG L√ÅI XE!\nVui l√≤ng t·∫≠p trung v√†o vi·ªác l√°i xe.',
      details,
    );

    print('‚ö†Ô∏è Warning notification sent');
  }

  Future<void> _logDrivingEvent() async {
    final event = {
      'timestamp': DateTime.now().toIso8601String(),
      'type': 'continuous_face_detected_while_driving',
      'detection_count': _faceDetectionCount,
      'warning_sent': true,
      'app_state': _currentAppState.toString(),
    };

    print('üìù Driving warning event logged: $event');
  }

  void dispose() {
    _detectionTimer?.cancel();
    _disposeCamera();
    _faceDetector.close();
  }
}
